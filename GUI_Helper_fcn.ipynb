{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22263b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wurun\\AppData\\Local\\Temp\\ipykernel_20624\\3439355931.py:5: DeprecationWarning: Please use `binary_fill_holes` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  from scipy.ndimage.morphology import binary_fill_holes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from scipy.fft import fft,rfft,rfftfreq, irfft\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.optimize import curve_fit\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import io\n",
    "from skimage.segmentation import flood\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import requests\n",
    "import queue \n",
    "import copy\n",
    "import pickle\n",
    "from mpl_interactions import hyperslicer\n",
    "from openpyxl import load_workbook\n",
    "from pylab import *\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4092c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setGlobal_GUI(fpsVal,scaleVal, name, aspectVal):\n",
    "    #set global parameters\n",
    "    #input:fpsVal: frame per second\n",
    "    #      scaleVal: pixel distance scale\n",
    "    #      name:sample name\n",
    "    #      aspectVal:aspect of image height width\n",
    "    global file_prefix\n",
    "    file_prefix = name\n",
    "    global fps\n",
    "    fps = fpsVal\n",
    "    global scale\n",
    "    scale = scaleVal\n",
    "    global sampleIndex\n",
    "    sampleIndex = name\n",
    "    global aspect\n",
    "    aspect = aspectVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a32b3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoIn(inputname):\n",
    "    #import video and perform basic noise reduction\n",
    "    #input:filename\n",
    "    #output:image array im (true false 3D array)\n",
    "    im = io.imread(inputname)  #all 0 1 entry\n",
    "    im = im.astype(bool)  #convert to true false entry\n",
    "\n",
    "    \n",
    "    for i in range(im.shape[0]):   #for each image slice\n",
    "        slice = ndimage.binary_closing(im[i,:,:], iterations = 1)  #binary closing of image to remove small holes\n",
    "        slice = morphology.remove_small_objects(slice,\n",
    "                                                    min_size= 100, connectivity=4)  #remove objects smaller than min size, connectivity\n",
    "                                                                                    #defines the neighborhood of a pixel\n",
    "        slice = ~slice  #invert true false entry\n",
    "        slice = ndimage.binary_closing(slice, iterations = 1)\n",
    "        im[i, :, :] = morphology.remove_small_objects(slice,\n",
    "                                                    min_size= 100, connectivity=4)  #repeat same process and update image array\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14aa4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def STmap(im, light_time = None,light_time_ob = None, light_distance = None,\n",
    "          c_low = None, c_high = None,d_min = None, d_max = None,t_min = None, t_max = None, \n",
    "          z_score = False, normalization = False, saveFlag = False):\n",
    "    #compute the spatial temporal map\n",
    "    #input: image matrix im (3D:slice x row number x column number)\n",
    "    #       the time for light stimulation: light_time\n",
    "    #       the observation time period after stimulation: light_time_ob\n",
    "    #       the distance of stimulation: light_distance\n",
    "    #       colormap lower limit: c_low (default: None)\n",
    "    #       colormap upper limit: c_high (default: None)\n",
    "    #       heatmap visualization distance lower limit: d_min (default:None)\n",
    "    #       heatmap visualization distance upper limit: d_max (default:None)\n",
    "    #       heatmap visualization time lower limit: t_min (default:None)\n",
    "    #       heatmap visualization time upper limit: t_max (default: None)\n",
    "    #       whether to output zscore matrix and plot: z_score (default: None)\n",
    "    #       whether to output normalized matrix with entry 0~1 and plot: normalization (default: None)\n",
    "    #       whether to save the figure: saveFlag (default: False)\n",
    "    #output: colormap of STmap, return STmap matrix\n",
    "    im_s_r = np.sum(~im, axis = 1)[:,1:-1]/scale #sum up along each column in each image slice\n",
    "                                 #turn row data in every column in each slice into one number: thickness/width of tissue\n",
    "                                 #dimension:slice number x column number\n",
    "    #filter out frames with low quality (noise frames)\n",
    "    im_s = []\n",
    "    for i in range(im_s_r.shape[0]):\n",
    "        row_quality = 1\n",
    "        for j in range(im_s_r.shape[1]):\n",
    "            if im_s_r[i][j] < 0.1:   #filter out regions with noises\n",
    "                row_quality = 0\n",
    "        if row_quality == 1:\n",
    "            im_s.append(im_s_r[i])\n",
    "    im_s = np.array(im_s)\n",
    "    \n",
    "    if z_score:  #if compute z score map\n",
    "        im_z = np.zeros(im_s.shape)  #initialize im z score matrix\n",
    "        for i in range(im_s.shape[1]):   #range through each column\n",
    "            im_z[:, i] = scipy.stats.zscore(im_s[:, i])\n",
    "        figType = \"Z_score_STmap\"\n",
    "        ST_map_visual(im_z,light_time,light_time_ob, light_distance, c_low, c_high,d_min, d_max,t_min, t_max,saveFlag, figType)\n",
    "        return im_z\n",
    "    elif normalization:  #if compute normalized map\n",
    "        im_p = np.zeros(im_s.shape)\n",
    "        for i in range(im_s.shape[1]):\n",
    "            im_p[:, i] = im_s[:, i]/np.max(im_s[:,i])\n",
    "        figType = \"Normalized_STmap\"\n",
    "        ST_map_visual(im_p,light_time,light_time_ob, light_distance,c_low, c_high,d_min, d_max,t_min, t_max,saveFlag, figType)\n",
    "        return im_p\n",
    "    else:\n",
    "        figType = \"Raw_diameter_STmap\"\n",
    "        ST_map_visual(im_s,light_time,light_time_ob, light_distance,c_low, c_high,d_min, d_max,t_min, t_max,saveFlag, figType)\n",
    "        return im_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a74b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ST_map_visual(im,light_time,light_time_ob, light_distance,c_low, c_high,d_min, d_max,t_min, t_max,saveFlag, figType):\n",
    "    #visualization for ST maps\n",
    "    #input: image matrix im (3D:slice x row number x column number)\n",
    "    #       the time for light stimulation: light_time\n",
    "    #       the observation time period after stimulation: light_time_ob\n",
    "    #       colormap lower limit: c_low (default: None)\n",
    "    #       colormap upper limit: c_high (default: None)\n",
    "    #       heatmap visualization distance lower limit: d_min (default:None)\n",
    "    #       heatmap visualization distance upper limit: d_max (default:None)\n",
    "    #       heatmap visualization time lower limit: t_min (default:None)\n",
    "    #       heatmap visualization time upper limit: t_max (default: None)\n",
    "    #       whether to save the figure: saveFlag\n",
    "    #       figure type among three: figType\n",
    "    #output: colormap of STmap\n",
    "    #plt.close(\"all\")\n",
    "    plt.figure()\n",
    "    plt.imshow(im, aspect = aspect, extent=[0,shape(im)[1]/scale,shape(im)[0]/fps,0])\n",
    "    if c_low is None:  \n",
    "        c_low = im.min()\n",
    "    if c_high is None:\n",
    "        c_high = im.max()\n",
    "    if d_min is None:  \n",
    "        d_min = 0\n",
    "    if d_max is None:\n",
    "        d_max = shape(im)[1]/scale\n",
    "    if t_min is None:  \n",
    "        t_min = 0\n",
    "    if t_max is None:\n",
    "        t_max = shape(im)[0]/fps              \n",
    "    plt.set_cmap('jet')\n",
    "    plt.colorbar()\n",
    "    plt.clim([c_low, c_high])\n",
    "    plt.xlim([d_min,d_max])\n",
    "    plt.ylim([t_max,t_min])\n",
    "    plt.xlabel(\"Distance(cm)\")\n",
    "    plt.ylabel(\"Time(s)\")\n",
    "    plt.show()\n",
    "    if light_time != None:\n",
    "        for i in light_time:\n",
    "            plt.axhline(y = i, color='white', linestyle='-')\n",
    "            plt.axhline(y = i + light_time_ob, color='white', linestyle='--')\n",
    "    if light_time !=None:\n",
    "        plt.axvline(x = light_distance/scale, color='white', linestyle='-')\n",
    "    if saveFlag == True:\n",
    "        plt.savefig(\"STmap/{}_{}.pdf\".format(figType,sampleIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "693ddc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dmap3D(im):\n",
    "    #compute 3D plot for diameter, x axis represent time, y axis represent distance\n",
    "    #input: 2D image array: im\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    X = np.linspace(0, shape(im_s)[1]/scale, num=shape(im_s)[1]) #distance\n",
    "    Y = np.linspace(0, shape(im_s)[0]/fps, num=shape(im_s)[0]) #time\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(X, Y, im, cmap=cm.coolwarm,rstride=1, cstride=1,\n",
    "                           linewidth=0, antialiased=True)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel(\"Distance(cm)\")\n",
    "    ax.set_ylabel(\"Time(s)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17e143ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DmapFreqFFTVis(im_s, position):\n",
    "    #compute 2D diameter plot at specific distance and perform fourier transform to extract frequency information\n",
    "    #input: 2D image array: im_s\n",
    "    #       the position index at distance map: position\n",
    "    Tarray = np.linspace(0, shape(im_s)[0]/fps, num=shape(im_s)[0]) #time\n",
    "    Darray = im_s[:,position] #get diameter at specific distance \n",
    "    Darray = ndimage.gaussian_filter1d(Darray, 50)  #smooth the curve\n",
    "    Darrayfreqy = rfft(Darray)\n",
    "    Darrayfreqx = rfftfreq(shape(im_s)[0],1/fps)  #perform fourier transform\n",
    "    DarrayInv = irfft(Darrayfreqy, Darray.shape[0])   #perform inverse fourier transform to see if features are captured and preserved\n",
    "    plt.figure(figsize = (8,18))\n",
    "    subplot(4,1,1)\n",
    "    plt.plot(Tarray, Darray)\n",
    "    plt.xlabel(\"Time(s)\")\n",
    "    plt.ylabel(\"Diameter(cm)\")\n",
    "    plt.title(\"Diameter time domain change along position x = %d of original data\" % position)\n",
    "    subplot(4,1,2)\n",
    "    plt.plot(Darrayfreqx, np.abs(Darrayfreqy))\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.xlabel(\"Frequency(Hz)\")\n",
    "    plt.title(\"Diameter frequency domain change along position x = %d via fourier transform\" % position)\n",
    "    subplot(4,1,3)\n",
    "    plt.plot(Darrayfreqx, np.abs(Darrayfreqy))\n",
    "    secondmax = sorted(np.abs(Darrayfreqy))[-2]\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.xlabel(\"Frequency(Hz)\")\n",
    "    plt.xlim([0,0.5])\n",
    "    plt.ylim([0,secondmax*1.2])\n",
    "    plt.title(\"Diameter zoomed in frequency domain change along position x = %d via fourier transform\" % position)\n",
    "    subplot(4,1,4)\n",
    "    plt.plot(Tarray, DarrayInv)\n",
    "    plt.xlabel(\"Time(s)\")\n",
    "    plt.ylabel(\"Diameter(cm)\")\n",
    "    plt.title(\"Diameter time domain change along position x = %d via inverse fourier transform\" % position)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "719a1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DmapFreqMean(im_s, position):\n",
    "    #calculate mean frequency at specific distance point over time from fourier transform\n",
    "    #input: 2D image array: im_s\n",
    "    #       the position index at distance map: position\n",
    "    #output: mean frequency\n",
    "    Tarray = np.linspace(0, shape(im_s)[0]/fps, num=shape(im_s)[0]) #time\n",
    "    Darray = im_s[:,position] #get diameter at specific distance \n",
    "    Darray = ndimage.gaussian_filter1d(Darray, 50)  #smooth the curve\n",
    "    Darrayfreqy = rfft(Darray)\n",
    "    Darrayfreqx = rfftfreq(shape(im_s)[0],1/fps)  #perform fourier transform\n",
    "    #calculate power \n",
    "    power = np.abs(Darrayfreqy) ** 2\n",
    "    freq_mean = (sum(power*Darrayfreqx))/sum(power)\n",
    "    return freq_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "329943e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DmapFreqMode(im_s, position):\n",
    "    #calculate mode frequency at specific distance point over time from fourier transform\n",
    "    #mode frequency: frequency with highest amplitude\n",
    "    #input: 2D image array: im_s\n",
    "    #       the position index at distance map: position\n",
    "    #output: mode frequency\n",
    "    Tarray = np.linspace(0, shape(im_s)[0]/fps, num=shape(im_s)[0]) #time\n",
    "    Darray = im_s[:,position] #get diameter at specific distance \n",
    "    Darray = ndimage.gaussian_filter1d(Darray, 50)  #smooth the curve\n",
    "    Darrayfreqy = rfft(Darray)\n",
    "    Darrayfreqx = rfftfreq(shape(im_s)[0],1/fps)  #perform fourier transform\n",
    "    #find mode frequency\n",
    "    maxindex = np.argsort(Darrayfreqy)[-2]  #get second max because the maximum is always at freq = 0 \n",
    "    freq_mode = Darrayfreqx[maxindex]\n",
    "    return freq_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72226e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegionMeanFreqMode(im_s,Dmin = 0, Dmax = None, Tmin = 0, Tmax = None):\n",
    "    #calculate the mean of the nonzero frequency mode\n",
    "    #input: im_s: image array\n",
    "    #       Dmin, Dmax, Tmin, Tmax: the region bbox to evaluate on\n",
    "    \n",
    "    if Dmax == None:\n",
    "        Dmax = im_s.shape[1]/scale\n",
    "    if Tmax == None:\n",
    "        Tmax = im_s.shape[0]/fps\n",
    "    im_s_evaluated = im_s[int(floor(Tmin*fps)):int(floor(Tmax*fps)),int(floor(Dmin*scale)):int(floor(Dmax*scale))]\n",
    "    FreqMode = []\n",
    "    for position in range(im_s_evaluated.shape[1]):\n",
    "        FreqMode.append(DmapFreqMode(im_s_evaluated, position))\n",
    "    return mean(FreqMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d504de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureHeatmap(im_s):\n",
    "    #plot heatmap for all features\n",
    "    #input: im_s: raw diameter of image array\n",
    "    feature_num = 2  #feature 0:mean frequency; feature 1: nonzero mode frequency\n",
    "    slice_num = int(shape(im_s)[1])\n",
    "    mtx = np.zeros((feature_num, slice_num))\n",
    "    for i in range(slice_num):\n",
    "        mtx[0,i] = DmapFreqMean(im_s,i)\n",
    "        mtx[1,i] = DmapFreqMode(im_s,i)\n",
    "    num_ticks = 10\n",
    "    # the index of the position of yticks\n",
    "    xticks = np.linspace(0, slice_num - 1, num_ticks, dtype=int)\n",
    "    distance = np.linspace(0, shape(im_s)[1]/scale, num=shape(im_s)[1]) #distance\n",
    "    xticklabels =  [\"{:.2f}\".format(distance[idx]) for idx in xticks]\n",
    "    # the content of labels of these yticks\n",
    "    plt.figure(figsize = (6,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    ax1 = sns.heatmap(mtx[0,:].reshape(1,-1), cmap=\"YlGnBu\",xticklabels=xticklabels,yticklabels = [\"Mean Frequency\"])\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels(xticklabels,rotation=20)\n",
    "    ax1.set_xlabel(\"Distance(cm)\")\n",
    "    plt.subplot(2,1,2)\n",
    "    ax2 = sns.heatmap(mtx[1,:].reshape(1,-1), cmap=\"YlGnBu\",xticklabels=xticklabels,yticklabels = [\"Mode Frequency\"])\n",
    "    ax2.set_xticks(xticks)\n",
    "    ax2.set_xticklabels(xticklabels,rotation=20)\n",
    "    ax2.set_xlabel(\"Distance(cm)\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a78322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find local minimum of STmap including on edges\n",
    "def find_local_min(im_s, im_z, time_sigma = 5, spatial_sigma = 2, \n",
    "                   time_width = 50, time_prominence = [0.25,], peak_filter = None):\n",
    "    #compute local minimum of a STmap in both row and column directions\n",
    "    #first identify the local minimum along column (time) and along row (spatial) and find intersection\n",
    "    #using padding and enable thresholding based on z score \n",
    "    #input: The raw image data array: im_s\n",
    "    #       The z score image data array: im_z\n",
    "    #       standard deviation for gaussian 1D filter in column local minimum identification: time_sigma, default = 5\n",
    "    #       standard deviation for gaussian 1D filter in row local minimum identification: peak_filter, default = 2\n",
    "    #       width parameter in identify peaks along column: time_width, default = 50\n",
    "    #       prominence parameter in identify peaks along column: time_prominence, default = [0.25,]\n",
    "    #       whether to use z score to filter peaks: peak_filter, default = None\n",
    "    #output: The computed z score image data array: im_z_r\n",
    "    #        The computed raw image data array: im_s_r\n",
    "    #        row peaks(y coordinates): peak_x\n",
    "    #        columnb peaks(x coordinates): peak_y\n",
    "    \n",
    "    #find local minimal in columns (time\n",
    "    im_z_r = im_z.max()- im_z\n",
    "    im_z_r = ndimage.gaussian_filter1d(im_z_r, sigma = time_sigma) #apply 1d guassian filter, sigma: standard deviation for Gaussian kernel\n",
    "                                                                   #may be filter in individual direction?\n",
    "    \n",
    "    #perform padding around the image edge\n",
    "    #padding tensors is adding zeros around the border of images to convert them to a shape that \n",
    "    #is amenable to the convolution operation without throwing away any pixel information\n",
    "    orig_y, orig_x = im_z_r.shape\n",
    "    pad_x = round(0.07 * im_z_r.shape[1])\n",
    "    pad_x = pad_x if pad_x > 10 else 10  #set minimum pad x to be 10\n",
    "    pad_y = round(0.07 * im_z_r.shape[0])\n",
    "    pad_y = pad_y if pad_y > 100 else 100  #set minimum pad y to be 100\n",
    "    im_z_r = np.pad(im_z_r, ((pad_y,pad_y),(pad_x,pad_x)), mode = \"symmetric\")\n",
    "    #find local maximum along the array\n",
    "    peakplot_c = np.zeros(im_z_r.shape)\n",
    "    for i in range(im_z_r.shape[1]):\n",
    "        peaks, _= scipy.signal.find_peaks(im_z_r[:, i], width = time_width, prominence = time_prominence) \n",
    "                    #The prominence of a peak measures how much the peak \n",
    "                    #stands out due to its intrinsic height and its location relative to other peaks\n",
    "        for peak in peaks:\n",
    "            peakplot_c[peak, i] = 1\n",
    "\n",
    "    #find local minimal in rows\n",
    "    im_s_r = im_s.max() - im_s\n",
    "    if spatial_sigma != 0:\n",
    "        im_s_r = ndimage.gaussian_filter1d(im_s_r, sigma = spatial_sigma)\n",
    "    im_s_r = np.pad(im_s_r, ((pad_y,pad_y),(pad_x,pad_x)), mode = \"symmetric\")\n",
    "    peakplot_r = np.zeros(im_s_r.shape)\n",
    "    for i in range(im_s_r.shape[0]):\n",
    "        peaks, _= scipy.signal.find_peaks(im_s_r[i, :])\n",
    "        for peak in peaks:\n",
    "            peakplot_r[i, peak] = 1\n",
    "            \n",
    "    #find the intersection between row and column minimum\n",
    "    peakplot = peakplot_r * peakplot_c\n",
    "    [peak_y, peak_x] = np.where(peakplot == 1)\n",
    "    \n",
    "    peak_x = peak_x - pad_x\n",
    "    peak_y = peak_y - pad_y\n",
    "    index = []\n",
    "    #filter out the ones in added buffer edge\n",
    "    for i in range(len(peak_y)): \n",
    "        if peak_x[i] < -1 or peak_x[i] >= orig_x or peak_y[i] < 0 or peak_y[i] >= orig_y:\n",
    "            index += [i]\n",
    "        if peak_x[i] == -1:\n",
    "            peak_x[i] = 0\n",
    "    index = np.array(index)\n",
    "    peak_x = np.delete(peak_x, index)\n",
    "    peak_y = np.delete(peak_y, index)\n",
    "    # focus only on the region of interest (discard the added edges)\n",
    "    im_z_r = im_z_r[pad_y:-pad_y, pad_x:-pad_x]\n",
    "    im_s_r = im_s_r[pad_y:-pad_y, pad_x:-pad_x]\n",
    "    \n",
    "    #filter peaks based on z-score\n",
    "    #the local maximum is defined as a peak if over certain threshold defined based on z score \n",
    "    if peak_filter != None:\n",
    "        percentile = np.percentile(im_z_r, peak_filter, axis = 0 )\n",
    "        index = []\n",
    "        for i in range(len(peak_x)):\n",
    "            if im_z_r[peak_y[i], peak_x[i]] < percentile[peak_x[i]]:\n",
    "                index += [i]\n",
    "        if len(index) != 0:\n",
    "            index = np.array(index)\n",
    "            peak_x = np.delete(peak_x, index)\n",
    "            peak_y = np.delete(peak_y, index)\n",
    "    return im_z_r, im_s_r, peak_x, peak_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab89a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_mask(im_z_r, peak_x, peak_y):\n",
    "    #generate combined mask through flooding \n",
    "    #input: the local mimnimumly processed z score image array: im_z_r\n",
    "    #       coordinates for peaks: peak_x, peak_y\n",
    "    #output: the computed combined mask and visualized\n",
    "    dot_queue = queue.Queue()\n",
    "    dot_set = set()\n",
    "    value = np.zeros(peak_x.shape)\n",
    "    for i in range(peak_x.shape[0]):\n",
    "        value[i] = im_z_r[peak_y[i], peak_x[i]]  #put the peak values in an array\n",
    "                                                 \n",
    "    index = np.argsort(-1*value) #get the descending index of sorted peak values\n",
    "    for i in index:\n",
    "        dot_queue.put((peak_x[i], peak_y[i]))  #put peak values in queue\n",
    "        dot_set.add((peak_x[i], peak_y[i]))   #put peak values in set\n",
    "\n",
    "    i = 0\n",
    "    mask_c = np.zeros(im_z_r.shape)\n",
    "    while len(dot_set) > 0:       \n",
    "        seed = dot_queue.get()  #Remove and return an item from the queue\n",
    "        if seed in dot_set:\n",
    "            i += 1\n",
    "            mask = oneSeed(seed, dot_set, im_z_r, 0.1, rate = 0.1)  #generate mask around the seed                            \n",
    "            mask_c[mask & (mask_c == 0)] = i  #set the intersection of originally blank mask and wanted mask to be iteration number\n",
    "                                            #why want iteration number i not 1?\n",
    "    \n",
    "    return mask_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba8620c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneSeed(seed, dot_set, im_z, tol = 0.12, rate = 0.8):\n",
    "    #generate flooding of one mask from one seed of peak point with combined information of other dots in mask\n",
    "    #input: the flooding orgin peak point: seed\n",
    "    #       the set of peak points: dot_set\n",
    "    #       the z-score image array: im_z\n",
    "    #       tolerance coefficient for flooding: tol (default: 0.12)\n",
    "    #       rate coefficient for flooding: rate (default: 0.8)\n",
    "    #output: the mask around the seed\n",
    "    add_iter = 0\n",
    "    #Mask corresponding to a flood fill.\n",
    "    #Starting at a specific seed_point, connected points equal or within tolerance of the seed value are found.\n",
    "    mask = flood(im_z, (seed[1],seed[0]), connectivity = 8, \n",
    "                 tolerance = tol*np.power(rate, add_iter)*im_z[seed[1],seed[0]]) #points with value within tolerance will be included in flooding area\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        added_dot = set()\n",
    "        for dot in dot_set:\n",
    "            #print(\"check:\")\n",
    "            #print(dot)\n",
    "            if dotIsIn(dot[1], dot[0], mask): #if other dot is in mask, update the mask by adding the flood of those dots as well\n",
    "                #print(\"add:\")\n",
    "                #print(dot)\n",
    "                added_dot.add(dot)\n",
    "                mask1 = flood(im_z, (dot[1], dot[0]), connectivity = 8, \n",
    "                              tolerance = tol*(im_z[seed[1],seed[0]]+\n",
    "                              im_z[dot[1], dot[0]])/2)  #use new tolerance and flood origin to generate new masks\n",
    "                mask = mask | mask1 #add mask 1 to mask\n",
    "        for dot in added_dot:\n",
    "            dot_set.remove(dot) #remove dot in dot set if added to the flooding of the mask\n",
    "        add_iter += 1\n",
    "        if len(added_dot) == 0:\n",
    "            break       \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43f18608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotIsIn(dot_y, dot_x, mask):\n",
    "    #check if dot is in the mask\n",
    "    #input: y axis coordinate of dot: dot_y\n",
    "    #       x axis coordinate of dot: dot_x\n",
    "    #       mask to be checked: mask\n",
    "    #output: return true if dot in mask, return false if dot not in mask\n",
    "    return (mask[dot_y, dot_x] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0843608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealRegions(mask_c, size_low_limit = 400):\n",
    "    #anneal regions in mask and delete those under thershold\n",
    "    #input: the mask to anneal: mask_c\n",
    "    #       minimum size to remain after annealing: size_low_limit (default:400)\n",
    "    #output: annealed mask mask_c\n",
    "    properties = regionprops(mask_c.astype(int)) #measure the property of the region marked\n",
    "    i = 1 #index of labeled region\n",
    "    while True:\n",
    "        #set solidity as standard for whether to anneal regions and termination\n",
    "        #Ratio of pixels in the region to pixels of the convex hull image\n",
    "        if properties[-i].solidity > 0.73 or i >= len(properties):\n",
    "            break\n",
    "        else:\n",
    "            #delete regions that are too small (thresholded by solidity)\n",
    "            mask_c[mask_c == (mask_c.max() - i + 1)] = 0\n",
    "            print(\"mask \", mask_c.max() - i + 1, \"= 0\")\n",
    "        i += 1\n",
    "    \n",
    "    #count regions to be removed\n",
    "    to_remove = len(properties) - i + 1\n",
    "    \n",
    "    for i in np.arange(1, len(properties)):\n",
    "        #print(\"threshold:\", round(to_remove))\n",
    "        if i <= to_remove: \n",
    "            mask_c = anneal(i, mask_c)\n",
    "            #whatever, close the region using binary fill holes\n",
    "            mask_c[binary_fill_holes(mask_c == i)] = i\n",
    "            #delete regions that are too small after annealing\n",
    "            if (mask_c == i).sum() < size_low_limit:\n",
    "                #print(\"shape \",i, \" is deleted because too small\")\n",
    "                mask_c[mask_c == i] = 0\n",
    "    return mask_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6013ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anneal(marker, mask_c):\n",
    "    #anneal regions given mask and marker level (helper function in annealRegions())\n",
    "    #input: anneal marker level: marker\n",
    "    #       mask to be annealed: mask_c\n",
    "    #output: annealed mask mask_c\n",
    "    for j in np.arange(1, mask_c.max()):\n",
    "        j_sum = (mask_c == j).sum()\n",
    "        #print(\"j is \", j,\"j sum is: \", j_sum)\n",
    "        if (j != marker)& (j_sum > 0): \n",
    "            #print(\"try to anneal: \", marker, j)\n",
    "            mask_j = mask_c == j  #get the entries where mask_c equal to level j\n",
    "            mask_marker = mask_c == marker  #get the entries where mask_c equal to set standard marker\n",
    "            #perform binary dilation\n",
    "            #the locus of the points covered by the structuring element, when its center lies within the non-zero points of the image\n",
    "            #get the overlapping region of two annealed masks\n",
    "            result = (binary_dilation(mask_j, np.ones((3,3))) & binary_dilation(mask_marker, \n",
    "                                                                          np.ones((3,3)))).sum()\n",
    "            #print(\"overlap result\",marker, \" and \", j,\" = \", result)\n",
    "            if  result!= 0:\n",
    "                print(\"annealing:\", marker, \" and \", j)\n",
    "                mask_c[mask_marker] = 0\n",
    "                mask_c[mask_j] = 0\n",
    "                mask_c[mask_j | mask_marker] = marker\n",
    "    return mask_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61eb11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_regions(mask_c, solidity_min = 0.5):\n",
    "    #filter regions by using binary erosion and dilation\n",
    "    #input: mask to be filtered: mask_c\n",
    "    #       minimum solidity allowed after erosion and dilation: solidity_min\n",
    "    #output: mask filtered: mask_c\n",
    "    properties = regionprops(mask_c.astype(int))\n",
    "    print(\"number of regions identified: \", len(properties))\n",
    "\n",
    "    i = 0\n",
    "    for prop in properties:\n",
    "        i += 1\n",
    "        # if convex shape, discard\n",
    "        if mask_c[round(prop.centroid[0]), round(prop.centroid[1])] == 0:\n",
    "            print(\"centroid zero:\", i)\n",
    "            mask_c[mask_c == i] = 0 \n",
    "\n",
    "        elif prop.solidity < solidity_min:\n",
    "            print(\"small solidity:\",i)\n",
    "            curr = mask_c == i\n",
    "            footprint = np.ones((15,15))\n",
    "            #perform erosion and dilation\n",
    "            new_curr = binary_erosion(curr, np.ones((15, 15)))\n",
    "            new_curr = binary_dilation(new_curr, np.ones((7,7)))\n",
    "            curr_prop = regionprops(new_curr.astype(int))\n",
    "            print(len(curr_prop))\n",
    "            if new_curr.sum() < 0.2 * prop.area:\n",
    "                print(\"remove\", i, \"due to diminish to zero\")\n",
    "                mask_c[mask_c == i] = 0  \n",
    "            elif curr_prop[0].solidity < prop.solidity:\n",
    "                print(\"remove \", i, \"due to small solidity\")\n",
    "                mask_c[mask_c == i] = 0\n",
    "            else:\n",
    "                mask_c[mask_c == i] = 0\n",
    "                mask_c[new_curr & (mask_c == 0)] = i #set the intersection of two masks\n",
    "\n",
    "    properties = regionprops(mask_c.astype(int))     \n",
    "    print(\"number of regions left: \",len(properties))\n",
    "    return mask_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "038693f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mask_c(mask_c):\n",
    "    #clean mask\n",
    "    #input: mask mask_c\n",
    "    #output: cleaned version mask_c\n",
    "    i = 1\n",
    "    for j in np.arange(1, mask_c.max()+1):\n",
    "        mask_curr = mask_c == j\n",
    "        if mask_curr.sum() > 0: #if occurence of level j is nonzero\n",
    "            mask_c[mask_curr] = i\n",
    "            i += 1    #reassign value\n",
    "    #plt.close(\"all\")\n",
    "    plt.figure()\n",
    "    plt.imshow(mask_c, aspect = aspect, extent=[0,shape(mask_c)[1]/scale,shape(mask_c)[0]/fps,0])\n",
    "    #add annotation to each region\n",
    "    properties = regionprops(mask_c.astype(int))\n",
    "    for i in np.arange(1, mask_c.max()+1):\n",
    "        mask_curr = mask_c == i\n",
    "        coord = [properties[int(i-1)].centroid[1]/scale,properties[int(i-1)].centroid[0]/fps]\n",
    "        plt.annotate(str(int(i)),coord,color='white',weight=\"bold\")\n",
    "    plt.show()\n",
    "    return mask_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a14c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mask_c_GUI(mask_c, x_inch, y_inch, dpi, file_prefix):\n",
    "    #clean mask for GUI\n",
    "    #input: mask mask_c\n",
    "    #       x_inch: x size of the mask\n",
    "    #       y_inch: y size of the mask\n",
    "    #       dpi: resolution\n",
    "    #       file_prefix: the filename\n",
    "    i = 1\n",
    "    for j in np.arange(1, mask_c.max()+1):\n",
    "        mask_curr = mask_c == j\n",
    "        if mask_curr.sum() > 0: #if occurence of level j is nonzero\n",
    "            mask_c[mask_curr] = i\n",
    "            i += 1    #reassign value\n",
    "    fig = plt.figure(frameon=False, figsize=(x_inch, y_inch), dpi=dpi)\n",
    "    ax  = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(mask_c, aspect=\"auto\")\n",
    "    fig.savefig(f\"{file_prefix}_reindexed.png\", dpi=dpi)\n",
    "    return mask_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72915d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionEllipsePropertyDisp(mask_c, im_z):\n",
    "    #display region properties on mask based on the assumption that the regions are ellpises\n",
    "    #input: mask to be analyzed: mask_c\n",
    "    #       image array im_z\n",
    "    properties = regionprops(mask_c.astype(int))\n",
    "    i = 0\n",
    "    for prop in properties:\n",
    "        i = i+1\n",
    "        print(i)\n",
    "        print(\"next one:\")\n",
    "        print(\"area:\", prop.area)\n",
    "        print(\"bbox\", prop.bbox)\n",
    "        print(\"centroid z depth:\", im_z[round(prop.centroid[0]), round(prop.centroid[1])])\n",
    "        print(\"area_convex\", prop.area_convex)\n",
    "        print(\"area_filled:\", prop.area_filled)\n",
    "        print(\"axis_major_length\", prop.axis_major_length)\n",
    "        print(\"axis_minor_length\", prop.axis_minor_length)\n",
    "        print(\"centroid:\", prop.centroid)\n",
    "        print(\"eccentricity:\", prop.eccentricity)\n",
    "        print(\"orientation\", prop.orientation)\n",
    "        print(\"perimeter/area\", prop.perimeter/prop.area)\n",
    "        print(\"solidity\", prop.solidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b6054ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetection_GUI(mask_c, x_inch, y_inch, dpi, file_prefix, threshold1=10, threshold2=150, FigDisplay=False):\n",
    "    #edge detection for all labled region\n",
    "    #input:mask_c: mask with labeled region\n",
    "    #       x_inch: x size of the mask\n",
    "    #       y_inch: y size of the mask\n",
    "    #       dpi: resolution\n",
    "    #       file_prefix: the filename\n",
    "    #      threshold1:lower threshold for sobel edge detection(default: 100)\n",
    "    #      threshold2:upper threshold for sobel edge detection(default: 150)\n",
    "    #output: visualization for all edge detection\n",
    "    #        return all edge edges_all\n",
    "    mask_curr_all = mask_c != 0  #get all nonzero region\n",
    "    mask_curr_all = mask_curr_all.astype(float)\n",
    "    img_blur_all = cv2.GaussianBlur(mask_curr_all, (3,3), 0)\n",
    "    sobelx    = cv2.Sobel(src=img_blur_all, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
    "    sobely    = cv2.Sobel(src=img_blur_all, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
    "    sobelxy   = cv2.Sobel(src=img_blur_all, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
    "    edges_all = cv2.Canny(image=(img_blur_all*255).astype(np.uint8), \n",
    "                          threshold1=threshold1, threshold2=threshold2)             # Canny Edge Detection\n",
    "\n",
    "    if display:\n",
    "        fig = plt.figure(frameon=False, figsize=(x_inch, y_inch), dpi=dpi)\n",
    "        ax  = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        ax.imshow(sobelx   , aspect='auto')\n",
    "        ax.imshow(sobely   , aspect='auto')\n",
    "        ax.imshow(sobelxy  , aspect='auto')\n",
    "        ax.imshow(edges_all, aspect='auto', cmap=\"binary\")\n",
    "        fig.savefig(f\"{file_prefix}_updated.png\", dpi=dpi)\n",
    "\n",
    "    output1 = np.maximum(sobelx, sobely)\n",
    "    output2 = np.maximum(sobelxy, edges_all)\n",
    "    overall = np.maximum(output1, output2)\n",
    "    return edges_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b49da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetectionIndividual_GUI(mask_c,regionIndex, threshold1=100, threshold2=150,FigDisplay = False):\n",
    "    #edge detection for one specific labled region for GUI\n",
    "    #input:mask_c: mask with labeled region\n",
    "    #      regionIndex: region index label for mask\n",
    "    #      threshold1:lower threshold for sobel edge detection(default: 100)\n",
    "    #      threshold2:upper threshold for sobel edge detection(default: 150)\n",
    "    #      FigDisplay:whether to display figure and save\n",
    "    #output: visualization for all edge detection\n",
    "    #        return all edge edges_all\n",
    "    mask_curr = mask_c == regionIndex  #grab specific region\n",
    "    mask_curr = mask_curr.astype(float)\n",
    "    img_blur = cv2.GaussianBlur(mask_curr, (3,3), 0)\n",
    "    sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
    "    sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
    "    sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
    "    edges = cv2.Canny(image=(img_blur*255).astype(np.uint8), threshold1 = threshold1, threshold2= threshold2) # Canny Edge Detection   \n",
    "    if FigDisplay == True:\n",
    "        fig = plt.figure()\n",
    "        ax  = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        fig.add_axes(ax)\n",
    "        ax.imshow(sobelx   , aspect='auto')\n",
    "        ax.imshow(sobely   , aspect='auto')\n",
    "        ax.imshow(sobelxy  , aspect='auto')\n",
    "        ax.imshow(edges, aspect='auto', cmap=\"binary\")\n",
    "        fig.savefig(f\"{file_prefix}_region{regionIndex}_edge.png\")\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41d94233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EdgeIndividualPivot_GUI(mask_c,regionIndex,FigDisplay = False):\n",
    "    #pivot the edges of individual contraction region to be the origin for start point for GUI\n",
    "    #input: mask_c: mask generated\n",
    "    #       regionIndex: region investigated\n",
    "    #       FigDisplay:whether to display figure and save\n",
    "    #output: X: 2D array with coordinates for repivoted edges\n",
    "    edges = edgeDetectionIndividual_GUI(mask_c,regionIndex, FigDisplay = False)\n",
    "    #detect wave front in selected region\n",
    "    start_f = 0\n",
    "    waveedgex = []\n",
    "    waveedgey = []\n",
    "    for i in range(edges.shape[0]):  #row index/time index\n",
    "            if sum(edges[i]) != 0: #when there is none zero index along the same time index\n",
    "                for j in range(edges.shape[1]): #column index/distance index\n",
    "                        if edges[i][j] != 0:  #assume leftmost leading front is the start point\n",
    "                            if start_f == 0:\n",
    "                                start_time = i\n",
    "                                start_distance  = j\n",
    "                                waveedgex.append(0) #the x coordinate is distance\n",
    "                                waveedgey.append(0)  #the y coordinate is time\n",
    "                                start_f = 1 \n",
    "                            else:\n",
    "                                time_val = (i - start_time)/fps\n",
    "                                distance_val = (j - start_distance)/scale\n",
    "                                waveedgex.append(distance_val)\n",
    "                                waveedgey.append(time_val)\n",
    "    X = []\n",
    "    for i in range(len(waveedgex)):\n",
    "        X.append([waveedgex[i], waveedgey[i]])   #note that X returned is sorted by y value\n",
    "    if FigDisplay == True:\n",
    "        waveedgey = np.array(waveedgey)\n",
    "        waveedgey = max(waveedgey) - waveedgey\n",
    "        fig = plt.figure()\n",
    "        plt.title(\"Wave edge repivoted for contraction region label = {}\".format(regionIndex))\n",
    "        plt.scatter(waveedgex,waveedgey)\n",
    "        plt.annotate(\"wave start point\",(0,max(waveedgey)),color='black',weight=\"bold\")\n",
    "        plt.ylabel(\"Pivoted Time(s)\")\n",
    "        plt.xlabel(\"Pivoted Distance(s)\")\n",
    "        fig.savefig(f\"{file_prefix}_region{regionIndex}_repivoted.png\")\n",
    "    return [X,start_time,start_distance]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2069b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpropagationDir_GUI(mask_c,regionIndex,FigDisplay = False):\n",
    "    #determine the propagation direction of the region for GUI\n",
    "    #either be anterograde, retrograde, bidirectional propagation\n",
    "    #input: mask_c: mask generated\n",
    "    #       regionIndex: region investigated\n",
    "    #      FigDisplay:whether to display figure and save\n",
    "    #output: propagation_dir: type of propagation\n",
    "    [X,start_time,start_distance] = EdgeIndividualPivot_GUI(mask_c,regionIndex,FigDisplay = FigDisplay)\n",
    "    X = np.array(sorted(X))  #sorted in ascending order\n",
    "    if X[0,0] == 0:\n",
    "        propagation_dir = \"anterograde propagation\"\n",
    "    elif X[-1,0] == 0:\n",
    "        propagation_dir = \"retrograde propagation\"\n",
    "    else:\n",
    "        propagation_dir = \"bidirectional propagation\"\n",
    "    return propagation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58445ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnterogradeFront(X,tolerance_intercept = 0.1, tolerance_slope = 1000):\n",
    "    #wavefront detection for anterograde propagation\n",
    "    #input: X: 2D array for pivoted edge\n",
    "    #      tolerance_intercept: parameter for neighborhood detection mode (initial boost from zero)\n",
    "    #      tolerance_slope: parameter for neighborhood detection mode (subsequent slope)\n",
    "    #output: wavefront: 2D array for wavefront detected \n",
    "    wavefront = []\n",
    "    xpivot = 0\n",
    "    ypivot = 0\n",
    "    for i in range(X.shape[0]):  #go from left to right\n",
    "        if ypivot == 0:\n",
    "            if abs(X[i,1]) < tolerance_intercept: #initial neighborhood around origin\n",
    "                wavefront.append([X[i,0],X[i,1]])\n",
    "                xpivot = X[i,0]\n",
    "                ypivot = X[i,1]     \n",
    "        else:  #include if bounded in predefined box\n",
    "            if (X[i,1] > ypivot - (X[i,0] - xpivot)*tolerance_slope) & (X[i,1] < ypivot + (X[i,0] - xpivot)*tolerance_slope):\n",
    "                wavefront.append([X[i,0],X[i,1]])\n",
    "                xpivot = X[i,0]\n",
    "                ypivot = X[i,1] \n",
    "    return wavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf20c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrogradeFront(X,tolerance_intercept = 0.1, tolerance_slope = 1000):\n",
    "    #wavefront detection for retrograde propagation\n",
    "    #input: X: 2D array for pivoted edge\n",
    "    #      tolerance_intercept: parameter for neighborhood detection mode (initial boost from zero)\n",
    "    #      tolerance_slope: parameter for neighborhood detection mode (subsequent slope)\n",
    "    #output: wavefront: 2D array for wavefront detected \n",
    "    wavefront = []\n",
    "    xpivot = 0\n",
    "    ypivot = 0\n",
    "    for i in range(X.shape[0]-1, -1, -1):  #go from right to left\n",
    "        if ypivot == 0:\n",
    "            if abs(X[i,1]) < tolerance_intercept: #initial neighborhood around origin\n",
    "                wavefront.append([X[i,0],X[i,1]])\n",
    "                xpivot = X[i,0]\n",
    "                ypivot = X[i,1]     \n",
    "        else: #include if bounded in predefined box\n",
    "            if (X[i,1] < ypivot - (X[i,0] - xpivot)*tolerance_slope) & (X[i,1] > ypivot + (X[i,0] - xpivot)*tolerance_slope):\n",
    "                wavefront.append([X[i,0],X[i,1]])\n",
    "                xpivot = X[i,0]\n",
    "                ypivot = X[i,1] \n",
    "    return wavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d353634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveFrontDetection_GUI(mask_c,regionIndex,propagation_dir, Detectmode = \"DBSCAN\", anterograde_tolerance_intercept = 0.1, \n",
    "                       anterograde_tolerance_slope = 1000, retrograde_tolerance_intercept = 0.1, \n",
    "                       retrograde_tolerance_slope = 1000, FigDisplay = False):\n",
    "    #edge detection for one specific region\n",
    "    #input:mask_c: mask with labeled region\n",
    "    #      regionIndex: region index label for mask\n",
    "    #      propagation_dir: the type of propagation based on direction\n",
    "    #      detectMode: choose from two modes: DBSCAN unsupervised clustering OR neighborhood detection\n",
    "    #      anterograde_tolerance_intercept: parameter for neighborhood detection mode (initial boost from zero)\n",
    "    #      anterograde_tolerance_slope: parameter for neighborhood detection mode (subsequent slope)\n",
    "    #      retrograde_tolerance_intercept: parameter for neighborhood detection mode (initial boost from zero)\n",
    "    #      retrograde_tolerance_slope: parameter for neighborhood detection mode (subsequent slope)\n",
    "    #      FigDisplay:whether to display figure and save\n",
    "    #output: visualization for wavefront and waveback detection, wavefront detection\n",
    "    #        return coordinate points for wavefront  \n",
    "    #sanity check\n",
    "    if (Detectmode != \"DBSCAN\") & (Detectmode != \"neighborhood\"):\n",
    "        print(\"No method found!\")\n",
    "        return\n",
    "\n",
    "    if Detectmode == \"DBSCAN\":\n",
    "        [X,start_time,start_distance] = EdgeIndividualPivot_GUI(mask_c,regionIndex,FigDisplay = False)\n",
    "        #run unsupervised classification for wavefront and waveback\n",
    "        X = np.array(X)\n",
    "        clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "        if (len(np.unique(clustering.labels_)) == 2) &(propagation_dir != \"bidirectional propagation\"):  #check if DBSCAN generates two clusters as intended\n",
    "            #detect wavefront\n",
    "            class0_ind = []\n",
    "            class1_ind = []\n",
    "            for i in range(len(clustering.labels_)):\n",
    "                if clustering.labels_[i] == 0:\n",
    "                    class0_ind.append(i)\n",
    "                else:\n",
    "                    class1_ind.append(i)\n",
    "            if X[class0_ind[0]][1] < X[class1_ind[0]][1]:\n",
    "                wavefront_class = class0_ind\n",
    "            else:\n",
    "                wavefront_class = class1_ind\n",
    "            wavefront = np.array([X[i] for i in wavefront_class])\n",
    "        else:  #if DBSCAN failed, change to neighborhood method\n",
    "            Detectmode = \"neighborhood\"  #change detection method\n",
    "            \n",
    "    if Detectmode == \"neighborhood\":\n",
    "        [X,start_time,start_distance] = EdgeIndividualPivot_GUI(mask_c,regionIndex,FigDisplay = False)\n",
    "        X = np.array(sorted(X))\n",
    "        X_neg = []\n",
    "        X_pos = []\n",
    "        for i in range(X.shape[0]):\n",
    "            if X[i,0] <= 0:\n",
    "                X_neg.append([X[i,0],X[i,1]]) #get backward propagation part\n",
    "            if X[i,0] >= 0:\n",
    "                X_pos.append([X[i,0],X[i,1]]) #get forward propagation part\n",
    "        X_pos = np.array(X_pos)\n",
    "        X_neg = np.array(X_neg)\n",
    "        #forward wavefront\n",
    "        if propagation_dir == \"anterograde propagation\":\n",
    "            wavefront =  AnterogradeFront(X_pos,tolerance_intercept = anterograde_tolerance_intercept, tolerance_slope = anterograde_tolerance_slope)\n",
    "        elif propagation_dir == \"retrograde propagation\":\n",
    "            wavefront =  RetrogradeFront(X_neg,tolerance_intercept = retrograde_tolerance_intercept, tolerance_slope = retrograde_tolerance_slope)\n",
    "        elif propagation_dir == \"bidirectional propagation\":\n",
    "            \n",
    "            Forwardwavefront = AnterogradeFront(X_pos,tolerance_intercept = anterograde_tolerance_intercept, tolerance_slope = anterograde_tolerance_slope)\n",
    "            #backward wavefront\n",
    "            Backwardwavefront = RetrogradeFront(X_neg,tolerance_intercept = retrograde_tolerance_intercept, tolerance_slope = retrograde_tolerance_slope)\n",
    "\n",
    "            #check if any forward or backward waves are void\n",
    "            if len(Backwardwavefront) == 0:\n",
    "                propagation_dir = \"anterograde propagation\"\n",
    "            if len(Forwardwavefront) == 0:\n",
    "                propagation_dir = \"retrograde propagation\"\n",
    "            if (len(Backwardwavefront) == 0) & (len(Forwardwavefront) == 0):\n",
    "                print(\"Problematic contraction without propagation detection!\")\n",
    "                return\n",
    "            \n",
    "            Backlen = len(Backwardwavefront)\n",
    "            Backwardwavefront.extend(Forwardwavefront)\n",
    "            wavefront = Backwardwavefront\n",
    "            \n",
    "    #for all cases:\n",
    "    wavefront = np.array(wavefront)\n",
    "    wavefront[:,1] = max(wavefront[:,1]) - wavefront[:,1]\n",
    "    if FigDisplay == True:\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.title(\"wavefront detected for contraction region label = {}\".format(regionIndex))\n",
    "        plt.scatter(wavefront[:,0],wavefront[:,1])\n",
    "        plt.ylabel(\"Time(s)\")\n",
    "        plt.xlabel(\"Distance(cm)\")\n",
    "        fig.savefig(f\"{file_prefix}_region{regionIndex}_wavefront.png\")\n",
    "\n",
    "    #determine return type\n",
    "    if propagation_dir == \"bidirectional propagation\":\n",
    "        print(type(wavefront))\n",
    "        return [wavefront,Backlen]\n",
    "    else:\n",
    "        print(type(wavefront))\n",
    "        return [wavefront]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9f43338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "    #define sigmoid curve for fitting of wavefront\n",
    "    #input: x: x coordinate\n",
    "    #       L:maximum point\n",
    "    #       x0: mid point for 50% maximum\n",
    "    #       k: slope for sigmoid curve\n",
    "    #       b: minimum point\n",
    "    #output: y: y coordinate of function\n",
    "    y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e9a0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidWaveFrontFit_GUI(wavefront,regionIndex,dirFlag, FigDisplay = False):\n",
    "    #add padded area on the left and right of the curve for GUI\n",
    "    #input: wavefront: wavefront edge\n",
    "    #       regionIndex: region index label for mask\n",
    "    #       dirFlag: specify propagation direction\n",
    "    #       FigDisplay:whether to display figure and save\n",
    "    #output: the visualization of sigmoidal curve fit\n",
    "    #        popt: the optimized parameter for sigmoid curve:[L, x0, k, b]\n",
    "    etd_len = int(shape(wavefront)[0]*0.5)\n",
    "    wavefront_extended = zeros([shape(wavefront)[0]+etd_len*2,shape(wavefront)[1]])\n",
    "    wavefront_extended[:etd_len,1] = wavefront[0,1]\n",
    "    wavefront_extended[-etd_len:,1] = wavefront[-1,1]\n",
    "    if wavefront[-1,0] > 0:  #forward propagation\n",
    "        wavefront_extended[:etd_len,0] = wavefront[0,0] - np.linspace(0.01*etd_len,0.01,etd_len)\n",
    "        wavefront_extended[-etd_len:,0] = wavefront[-1,0] + np.linspace(0.01, 0.01*etd_len,etd_len)\n",
    "    else:   #backward propagation\n",
    "        wavefront_extended[:etd_len,0] = wavefront[0,0] + np.linspace(0.01, 0.01*etd_len,etd_len)  \n",
    "        wavefront_extended[-etd_len:,0] = wavefront[-1,0] - np.linspace(0.01*etd_len,0.01,etd_len)\n",
    "\n",
    "    wavefront_extended[etd_len:-etd_len,:] = wavefront\n",
    "    xdata = wavefront_extended[:,0]\n",
    "    ydata = wavefront_extended[:,1]\n",
    "\n",
    "    p0 = [max(ydata), np.median(xdata),1,min(ydata)] # this is an mandatory initial guess\n",
    "    popt, pcov = curve_fit(sigmoid, xdata, ydata,p0, method='dogbox')\n",
    "    x = np.linspace(min(xdata), max(xdata), 100)\n",
    "    y = sigmoid(x, *popt)\n",
    "    if FigDisplay == True:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(xdata, ydata, 'o', label='data')\n",
    "        plt.plot(x,y, label='fit')\n",
    "        plt.title(\"Fitted {} wavefront for contraction region label = {}\".format(dirFlag, regionIndex))\n",
    "        plt.xlabel(\"Distance(cm)\")\n",
    "        plt.ylabel(\"Time(s)\")\n",
    "        plt.legend(loc='best')\n",
    "        fig.savefig(f\"{file_prefix}_region{regionIndex}_{dirFlag}_wavefrontSigmoidFit.png\")\n",
    "    return popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "534eb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propregionFeature_GUI(mask_c,im_z, im_s, regionIndex, contractionType, propagation_dir, Detectmode = \"DBSCAN\", \n",
    "                  anterograde_tolerance_intercept = 0.1, anterograde_tolerance_slope = 1000, \n",
    "                  retrograde_tolerance_intercept = 0.1, retrograde_tolerance_slope = 1000, FigDisplay = False):\n",
    "    #this funciton is for GUI\n",
    "    #display features of the region in contraction type under propagation family: propagation & interrupted small contraction\n",
    "    #input: mask_c: mask with labeled region\n",
    "    #       im_z: z score STmap\n",
    "    #       regionIndex: region index label for mask\n",
    "    #       contractionType: choose from two types of contraction: propagation OR interuppted small contraction\n",
    "    #       propagation_dir: propagation direction label: anterograde propagation OR retrograde propagation OR bidirectional propagation    \n",
    "    #       detectMode: choose from two wavefront detection modes: DBSCAN unsupervised clustering OR neighborhood detection\n",
    "    #       tolerance_intercept: parameter for neighborhood detection mode (initial boost from zero)\n",
    "    #       tolerance_slope: parameter for neighborhood detection mode (subsequent slope)\n",
    "    #      FigDisplay:whether to display figure and save\n",
    "    #output:featuredict: a dictionary of region properties\n",
    "    if (contractionType == \"propagation\") or (contractionType == \"interrupted small contraction\"):       \n",
    "        if propagation_dir == \"anterograde propagation\":\n",
    "            [wavefront] = waveFrontDetection_GUI(mask_c,regionIndex,propagation_dir, Detectmode = \"DBSCAN\", \n",
    "                                                 anterograde_tolerance_intercept = anterograde_tolerance_intercept, \n",
    "                                                 anterograde_tolerance_slope = anterograde_tolerance_slope, \n",
    "                                                 retrograde_tolerance_intercept = retrograde_tolerance_intercept, \n",
    "                                                 retrograde_tolerance_slope = retrograde_tolerance_slope, \n",
    "                                                 FigDisplay = FigDisplay)\n",
    "            featuredict = {}\n",
    "            featuredict[\"sample name\"] = file_prefix\n",
    "            dirFlag = \"anterograde\"\n",
    "            featuredict[\"class\"] = f\"{contractionType[:11]}_{dirFlag}\"\n",
    "            featuredict[\"region index\"] = f\"region {regionIndex}\"\n",
    "            featuredict[\"anterograde tolerance intercept\"] = anterograde_tolerance_intercept\n",
    "            featuredict[\"anterograde tolerance slope\"] = anterograde_tolerance_slope\n",
    "            featuredict[\"retrograde tolerance intercept\"] = retrograde_tolerance_intercept\n",
    "            featuredict[\"retrograde tolerance slope\"] = retrograde_tolerance_slope\n",
    "            featuredict = waveFrontFeature_GUI(featuredict,mask_c,regionIndex,wavefront,contractionType,dirFlag,FigDisplay)\n",
    "            featuredict = basicRegionFeature(featuredict,mask_c, im_z,im_s, regionIndex)\n",
    "            return featuredict\n",
    "        elif propagation_dir == \"retrograde propagation\":\n",
    "            [wavefront] = waveFrontDetection_GUI(mask_c,regionIndex,propagation_dir, Detectmode = \"DBSCAN\", \n",
    "                                                 anterograde_tolerance_intercept = anterograde_tolerance_intercept, \n",
    "                                                 anterograde_tolerance_slope = anterograde_tolerance_slope, \n",
    "                                                 retrograde_tolerance_intercept = retrograde_tolerance_intercept, \n",
    "                                                 retrograde_tolerance_slope = retrograde_tolerance_slope, \n",
    "                                                 FigDisplay = FigDisplay)\n",
    "            featuredict = {}\n",
    "            featuredict[\"sample name\"] = file_prefix\n",
    "            dirFlag = \"retrograde\"\n",
    "            featuredict[\"class\"] = f\"{contractionType[:11]}_{dirFlag}\"\n",
    "            featuredict[\"region index\"] = f\"region {regionIndex}\"\n",
    "            featuredict[\"anterograde tolerance intercept\"] = anterograde_tolerance_intercept\n",
    "            featuredict[\"anterograde tolerance slope\"] = anterograde_tolerance_slope\n",
    "            featuredict[\"retrograde tolerance intercept\"] = retrograde_tolerance_intercept\n",
    "            featuredict[\"retrograde tolerance slope\"] = retrograde_tolerance_slope\n",
    "            featuredict = waveFrontFeature_GUI(featuredict,mask_c,regionIndex,wavefront,contractionType,dirFlag, FigDisplay)\n",
    "            featuredict = basicRegionFeature(featuredict,mask_c, im_z, im_s,regionIndex)\n",
    "            return featuredict\n",
    "        elif propagation_dir == \"bidirectional propagation\":\n",
    "            [wavefront, Backlen] = waveFrontDetection_GUI(mask_c,regionIndex,propagation_dir, Detectmode = \"DBSCAN\", \n",
    "                                                 anterograde_tolerance_intercept = anterograde_tolerance_intercept, \n",
    "                                                 anterograde_tolerance_slope = anterograde_tolerance_slope, \n",
    "                                                 retrograde_tolerance_intercept = retrograde_tolerance_intercept, \n",
    "                                                 retrograde_tolerance_slope = retrograde_tolerance_slope, \n",
    "                                                 FigDisplay = FigDisplay)\n",
    "            \n",
    "            Forwardwavefront = wavefront[Backlen:]\n",
    "            Backwardwavefront = wavefront[:Backlen]\n",
    "            featuredict = {}\n",
    "            featuredict[\"sample name\"] = file_prefix\n",
    "            featuredict[\"class\"] = f\"{contractionType[:11]}_bidirectional\"\n",
    "            featuredict[\"region index\"] = f\"region {regionIndex}\"\n",
    "            featuredict[\"anterograde tolerance intercept\"] = anterograde_tolerance_intercept\n",
    "            featuredict[\"anterograde tolerance slope\"] = anterograde_tolerance_slope\n",
    "            featuredict[\"retrograde tolerance intercept\"] = retrograde_tolerance_intercept\n",
    "            featuredict[\"retrograde tolerance slope\"] = retrograde_tolerance_slope\n",
    "            dirFlag = \"anterograde\"\n",
    "            featuredict = waveFrontFeature_GUI(featuredict,mask_c,regionIndex,Forwardwavefront,contractionType,dirFlag,FigDisplay)\n",
    "            dirFlag = \"retrograde\"\n",
    "            featuredict = waveFrontFeature_GUI(featuredict,mask_c,regionIndex,Backwardwavefront,contractionType,dirFlag,FigDisplay)\n",
    "            featuredict = basicRegionFeature(featuredict,mask_c, im_z,im_s, regionIndex)\n",
    "\n",
    "            return featuredict\n",
    "    else:\n",
    "        print(\"Contraction type not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8020c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveFrontFeature_GUI(featuredict,mask_c,regionIndex,wavefront,contractionType,dirFlag, FigDisplay = False):\n",
    "    #extract features for wave front with fitted sigmoid curve\n",
    "    #input: featuredict:dictionary to put features\n",
    "    #       mask_c: mask generated\n",
    "    #       regionIndex: index of region\n",
    "    #       popt: fitted sigmoid curve\n",
    "    #       wavefront: wavefront array\n",
    "    #       contractionType: propagation OR interrupted contraction region\n",
    "    #       dirFlag: anterograde OR retrograde\n",
    "    #       FigDisplay:whether to display figure and save\n",
    "    #output: print the properties\n",
    "    #        return a list of property\n",
    "    [X,start_time,start_distance]= EdgeIndividualPivot_GUI(mask_c,regionIndex,FigDisplay = FigDisplay)\n",
    "    #basic scenario without fitting sigmoid curve\n",
    "    #calculate propagation start distance percentage position\n",
    "    propagation_start = start_distance/(mask_c.shape[1])\n",
    "    print(\"The\", dirFlag,\"propagation start point position percentage is:\", propagation_start*100,\"%\")\n",
    "    #calculate the propgation end distance percentage position\n",
    "    propagation_end = (start_distance/scale + wavefront[-1,0])/(mask_c.shape[1]/scale)\n",
    "    print(\"The\", dirFlag,\"propagation end point position percentage is:\", propagation_end*100,\"%\")\n",
    "    #calculate the propagation distance span\n",
    "    propagation_Dspan = max(wavefront[:,0]) - min(wavefront[:,0])\n",
    "    print(\"The\", dirFlag,\"propagation distance for the contraction is:\", propagation_Dspan,\"cm\")\n",
    "    #calculate the propagation distance percentage\n",
    "    propagation_Dper = propagation_Dspan/(mask_c.shape[1]/scale)\n",
    "    print(\"The\", dirFlag,\"propagation distance percentage is:\",propagation_Dper*100,\"%\")\n",
    "    #calculate the propagation time span\n",
    "    propagation_Tspan = max(wavefront[:,1]) - min(wavefront[:,1])\n",
    "    print(\"The\", dirFlag,\"propagation time for the contraction is:\", propagation_Tspan,\"s\")\n",
    "    #calculate overall velocity\n",
    "    overall_velocity = (max(wavefront[:,0]) - min(wavefront[:,0]))/(max(wavefront[:,1]) - min(wavefront[:,1]))\n",
    "    print(\"The overall\", dirFlag,\"propagation velocity for the contraction is:\", overall_velocity,\"cm/s\")\n",
    "    \n",
    "    if dirFlag == \"anterograde\":\n",
    "        featuredict[\"anterograde propagation start point percentage(%)\"] = propagation_start*100\n",
    "        featuredict[\"anterograde propagation end point percentage(%)\"] = propagation_end*100\n",
    "        featuredict[\"anterograde propagation distance span(cm)\"] = propagation_Dspan\n",
    "        featuredict[\"anterograde propagation distance percentage(%)\"] = propagation_Dper*100\n",
    "        featuredict[\"anterograde propagation time span(s)\"] = propagation_Tspan\n",
    "        featuredict[\"overall anterograde velocity(cm/s)\"] =overall_velocity \n",
    "    elif dirFlag == \"retrograde\":\n",
    "        featuredict[\"retrograde propagation start point percentage(%)\"] = propagation_start*100\n",
    "        featuredict[\"retrograde propagation end point percentage(%)\"] = propagation_end*100\n",
    "        featuredict[\"retrograde propagation distance span(cm)\"] = propagation_Dspan\n",
    "        featuredict[\"retrograde propagation distance percentage(%)\"] = propagation_Dper*100\n",
    "        featuredict[\"retrograde propagation time span(s)\"] = propagation_Tspan\n",
    "        featuredict[\"overall retrograde velocity(cm/s)\"] =overall_velocity \n",
    "\n",
    "    if contractionType == \"propagation\":\n",
    "        popt = sigmoidWaveFrontFit_GUI(wavefront,regionIndex,dirFlag,FigDisplay)\n",
    "        #calculate the propagation front slope mid point percentage position\n",
    "        propagation_mid = (start_distance/scale + popt[1])/(mask_c.shape[1]/scale)\n",
    "        print(\"The\", dirFlag,\"propagation mid point position percentage is:\", propagation_mid*100,\"%\")\n",
    "        #calculate the propagation front mid point slope\n",
    "        propagation_midslope = popt[2]\n",
    "        print(\"The\", dirFlag,\"propagation mid point slope is:\", propagation_midslope)\n",
    "        \n",
    "        if dirFlag == \"anterograde\":\n",
    "            featuredict[\"anterograde propagation max velocity position percentage(%)\"] = propagation_mid*100\n",
    "            featuredict[\"anterograde propagation max velocity(cm/s)\"] = propagation_midslope\n",
    "        elif dirFlag == \"retrograde\":\n",
    "            featuredict[\"retrograde propagation max velocity position percentage(%)\"] = propagation_mid*100\n",
    "            featuredict[\"retrograde propagation max velocity(cm/s)\"] = propagation_midslope\n",
    "\n",
    "    return featuredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab096f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicRegionFeature(featuredict,mask_c, im_z, im_s, regionIndex):\n",
    "    #extract features for wave front\n",
    "    #input: featuredict: dictionary to put features\n",
    "    #       mask_c: mask generated\n",
    "    #       im_z: z score image array\n",
    "    #       regionIndex: index of region\n",
    "    #output: print the properties\n",
    "    #        return a list of property\n",
    "    #other region properties relate to mask\n",
    "    properties = regionprops(mask_c.astype(int))\n",
    "    prop = properties[regionIndex-1]\n",
    "    contraction_area = prop.area/(scale*scale)\n",
    "    print(\"Contraction region area:\", contraction_area,\"cm^2\")\n",
    "\n",
    "    solidity = prop.solidity\n",
    "    print(\"Contraction region solidity: \", solidity)\n",
    "    centroid_time = prop.centroid[0]/fps\n",
    "    centroid_distance_per = prop.centroid[1]/im_z.shape[1]\n",
    "    print(\"Contraction centroid time position:\", centroid_time,\"s, distance position percentage:\",centroid_distance_per*100 ,\"%\")\n",
    "\n",
    "    #other region properties relate to intensity of z score STmap\n",
    "    im_z_mask = im_z.copy()\n",
    "    im_z_mask_lin = im_z_mask[mask_c == regionIndex]\n",
    "    intensity_max = im_z_mask_lin.min()\n",
    "    intensity_mean = im_z_mask_lin.mean()\n",
    "    #added for raw diameter\n",
    "    im_s_mask = im_s.copy()\n",
    "    im_s_mask_lin = im_s_mask[mask_c == regionIndex]\n",
    "    intensity_max_raw = im_s_mask_lin.min()\n",
    "    intensity_mean_raw = im_s_mask_lin.mean()\n",
    "    \n",
    "    im_z_mask[mask_c != regionIndex] = 0\n",
    "    intensity_max_coor_pixel = np.argwhere(im_z_mask == intensity_max)\n",
    "    intensity_max_coor_TD = intensity_max_coor_pixel.astype(float)\n",
    "    intensity_max_coor_TD[:,0] = intensity_max_coor_pixel[:,0]/fps\n",
    "    intensity_max_coor_TD[:,1] = intensity_max_coor_pixel[:,1]/scale    \n",
    "    \n",
    "    print(\"Maximum contraction intensity:\",intensity_max)\n",
    "    print(\"Raw diameter at maximum contraction intensity:\", intensity_max_raw)\n",
    "    print(\"Pixel coordinate of maximum contraction intensity is:\",intensity_max_coor_pixel)\n",
    "    print(\"Time distance coordinate of maximum contraction intensity is:\", intensity_max_coor_TD)\n",
    "    print(\"Mean contraction intensity:\",intensity_mean)\n",
    "    print(\"Raw diameter at mean contraction intensity:\", intensity_mean_raw)\n",
    "\n",
    "    \n",
    "    #write to dict\n",
    "    featuredict[\"contraction area(cm^2)\"] = contraction_area\n",
    "    featuredict[\"solidity\"] = solidity\n",
    "    featuredict[\"maximum z score contraction intensity\"] = intensity_max\n",
    "    featuredict[\"pixel coordinate of max z score contraction intensity\"] = intensity_max_coor_pixel\n",
    "    featuredict[\"time distance coordinate of max z score contraction intensity\"] = intensity_max_coor_TD\n",
    "    featuredict[\"mean z score contraction intensity\"] = intensity_mean\n",
    "    featuredict[\"time at contraction centroid(s)\"] = centroid_time\n",
    "    featuredict[\"distance percentage at contraction centroid(%)\"] = centroid_distance_per*100\n",
    "    featuredict[\"raw diameter at maximum contraction\"] = intensity_max_raw\n",
    "    featuredict[\"raw diameter at mean contraction\"] = intensity_mean_raw\n",
    "    \n",
    "    return featuredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "677d90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rippleregionFeature(mask_c,im_s, im_z,regionIndex,Dmin = 0, Dmax = None, Tmin = 0, Tmax = None):\n",
    "    #extract ripple features from specified regions\n",
    "    #input: mask mask_c\n",
    "    #       raw diameter STmap im_s\n",
    "    #       z score STmap im_z\n",
    "    #       region index regionIndex\n",
    "    #       distance left bound: Dmin\n",
    "    #       distance right bound: Dmax\n",
    "    #       Time left bound: Tmin\n",
    "    #       Time right bound: Tmax\n",
    "    #output: feature dictionary\n",
    "    if Dmax == None:\n",
    "        Dmax = im_s.shape[1]/scale\n",
    "    if Tmax == None:\n",
    "        Tmax = im_s.shape[0]/fps\n",
    "    featuredict = {}\n",
    "    Dstartper = Dmin/(im_s.shape[1]/scale)\n",
    "    print(\"The ripple region start point distance percentage is:\",Dstartper*100,\"%\")\n",
    "    Dendper = Dmax/(im_s.shape[1]/scale)\n",
    "    print(\"The ripple region end point distance percentage is:\",Dendper*100,\"%\")  \n",
    "    Dspan = Dmax - Dmin\n",
    "    print(\"The distance span of ripple region is:\",Dspan,\"cm\")\n",
    "    Tspan = Tmax - Tmin\n",
    "    print(\"The time span of ripple region is:\",Tspan,\"s\")\n",
    "    FreqMode = RegionMeanFreqMode(im_s,Dmin, Dmax, Tmin, Tmax)\n",
    "    print(\"The mean of nonzero mode frequency is:\",FreqMode)   \n",
    "    featuredict[\"sample name\"] = sampleIndex\n",
    "    featuredict[\"region index\"] = f\"region {regionIndex}\"\n",
    "    featuredict[\"class\"] = \"ripple\"\n",
    "    featuredict[\"distance start position percentage(%)\"] = Dstartper*100\n",
    "    featuredict[\"distance end position percentage(%)\"] = Dendper*100\n",
    "    featuredict[\"distance span(cm)\"] = Dspan\n",
    "    featuredict[\"time span(s)\"] = Tspan\n",
    "    featuredict[\"mean of mode ripple frequency(Hz)\"] = FreqMode\n",
    "    featuredict = basicRegionFeature(featuredict,mask_c, im_z,im_s, regionIndex)\n",
    "    return featuredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63b597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f212b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_to_results_GUI(sample_featuredict,filename):\n",
    "    #write results to existing excel that stores all results\n",
    "    #input: finalized sample_featuredict\n",
    "    #       excel filename to write final data to\n",
    "    ExcelWorkbook = load_workbook(filename)\n",
    "    writer = pd.ExcelWriter(filename, engine = 'openpyxl')\n",
    "    writer.book = ExcelWorkbook\n",
    "    #write each record to excel\n",
    "    for regionLabel,featuredict in sample_featuredict.items():\n",
    "        featuredf = pd.DataFrame(featuredict, index=[0])\n",
    "        sheetname = featuredf.loc[0][\"class\"]\n",
    "        featuredf.to_excel(writer,sheet_name=sheetname, startrow=writer.sheets[sheetname].max_row, index = False,header= False)\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82ff2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook GUI_Helper_fcn.ipynb to script\n",
      "[NbConvertApp] Writing 60317 bytes to GUI_Helper_fcn.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script GUI_Helper_fcn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0102a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996dc8a-6079-4ccd-9402-0fc7feb2e911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5de97a84-837a-4e9d-a3b6-36d97c15b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:0 for i in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f5195-fcfb-4ed5-a884-ba2aea4dcf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
